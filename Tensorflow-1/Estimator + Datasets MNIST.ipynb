{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction in to Datasets API and Estimator API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets and Estimators are two key TensorFlow features:\n",
    "\n",
    "- Datasets: Best practice way of creating input pipelines. Reading data in to your graph. \n",
    "- Estimators: A high-level API to create TensorFlow models. Estimators include canned models (out of the box) and custom estimators.\n",
    "\n",
    "Below you the TensorFlow architecture including the dataset API an Estimators. Combined, they offer an easy way to create TensorFlow models:\n",
    "\n",
    "![title](https://3.bp.blogspot.com/-l2UT45WGdyw/Wbe7au1nfwI/AAAAAAAAD1I/GeQcQUUWezIiaFFRCiMILlX2EYdG49C0wCLcBGAs/s1600/image6.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.0'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that we have correct TensorFlow version installed\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the MINST Data set that is around 12MB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Lets load in the data from the tutorials\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "data = input_data.read_data_sets('data/MNIST/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of:\n",
      "- Training-set:\t\t55000\n",
      "- Test-set:\t\t10000\n",
      "- Validation-set:\t5000\n"
     ]
    }
   ],
   "source": [
    "# Check the dataset size\n",
    "print(\"Size of:\")\n",
    "print(\"- Training-set:\\t\\t{}\".format(len(data.train.labels)))\n",
    "print(\"- Test-set:\\t\\t{}\".format(len(data.test.labels)))\n",
    "print(\"- Validation-set:\\t{}\".format(len(data.validation.labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes are one-hot encoded. So for each label we have a vector where all are zero but one. The index of the element is a class number. We need these class numbers as integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#np.argmax returns array of indeces\n",
    "data.train.cls = np.argmax(data.train.labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#np.argmax returns array of indeces\n",
    "data.test.cls = np.argmax(data.test.labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show traning labels for first ten. \n",
    "data.train.labels[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 3, 4, 6, 1, 8, 1, 0, 9, 8])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The class numbers that go with it. \n",
    "data.train.cls[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to specifiy the data dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MNIST images are 28 pixels by 28 pixels.\n",
    "img_size = 28\n",
    "\n",
    "# Image is a one-dimensional array of this size.\n",
    "img_size_flat = img_size * img_size\n",
    "\n",
    "# Tuple with height and width of images used to reshape arrays.\n",
    "img_shape = (img_size, img_size)\n",
    "\n",
    "# Number of colour channels for the images: 1 channel for gray-scale.\n",
    "num_channels = 1\n",
    "\n",
    "# Number of classes.\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper-function for plotting images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_images(images, cls_true, cls_pred=None):\n",
    "    assert len(images) == len(cls_true) == 9\n",
    "    \n",
    "    # Create figure with 3x3 sub-plots.\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Plot image.\n",
    "        ax.imshow(images[i].reshape(img_shape), cmap='binary')\n",
    "\n",
    "        # Show true and predicted classes.\n",
    "        if cls_pred is None:\n",
    "            xlabel = \"True: {0}\".format(cls_true[i])\n",
    "        else:\n",
    "            xlabel = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n",
    "\n",
    "        # Show the classes as the label on the x-axis.\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot a few images to see if data is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUMAAAD5CAYAAAC9FVegAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x125b27150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the first images from the test-set.\n",
    "images = data.test.images[0:9]\n",
    "\n",
    "# Get the true classes for those images.\n",
    "cls_true = data.test.cls[0:9]\n",
    "\n",
    "# Plot the images and labels using our helper-function above.\n",
    "plot_images(images=images, cls_true=cls_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Functions for the Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create a function that will return the data. This is to add flexibility and re-usability. We will be using the DNNClassifier so the data should be in intiger format. If we want we can also set paramaters here but in this case we will be loading data directly in to memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here we create are input function that takes in a numpay array. We can also specify the number of epochs and shuffle. \n",
    "# Here set input (x) and target (y)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(x={\"x\": np.array(data.train.images)},\n",
    "    y=np.array(data.train.cls),\n",
    "    num_epochs=None,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.estimator.inputs.numpy_io.input_fn>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This returns a function\n",
    "train_input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'x': <tf.Tensor 'random_shuffle_queue_DequeueMany_1:1' shape=(128, 784) dtype=float32>},\n",
       " <tf.Tensor 'random_shuffle_queue_DequeueMany_1:2' shape=(128,) dtype=int64>)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calling the function will return the tuple with TF ops.\n",
    "train_input_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We also need to create a function for the test set. \n",
    "test_input_fn= tf.estimator.inputs.numpy_input_fn(x={\"x\": np.array(data.test.images)},\n",
    "                                                 y=np.array(data.test.cls),\n",
    "                                                 num_epochs=1,\n",
    "                                                 shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'x': <tf.Tensor 'fifo_queue_DequeueUpTo_1:1' shape=(?, 784) dtype=float32>},\n",
       " <tf.Tensor 'fifo_queue_DequeueUpTo_1:2' shape=(?,) dtype=int64>)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# And lets take some images for doing the predictions. \n",
    "some_images = data.test.images[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Input function for predictions\n",
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'x': some_images},\n",
    "    num_epochs=1,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "some_images_cls = data.test.cls[0:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify the Canned Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The things we have done:\n",
    "- Load data. \n",
    "- Explore some of the data. \n",
    "- Create input function. \n",
    "\n",
    "Now it's time to setup an estimator. In this case we are going to use a pre-canned estimator: DNNClassifier. First we will setup the metadata information for the columns.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here we are specifying the type and column shape\n",
    "#feature_x = tf.feature_column.numeric_column('x', shape=img_shape) # x is the name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if we would have more features we have to put them together in a list. \n",
    "feature_columns = [tf.feature_column.numeric_column('x', shape=img_shape)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In this case we are building a three layer network. Here we specify the amount of hidden units\n",
    "num_hidden_units =[512, 256, 128] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x126512d50>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': './Checkpoints/checkpoints_tutorial17-1/', '_save_summary_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "#Now it's time to initiate our classifier. Here we also specify the feature columns, hidden units and activation function. \n",
    "# We are also going to save our checkpoints in a directory. \n",
    "model = tf.estimator.DNNClassifier(feature_columns=feature_columns,\n",
    "                                  hidden_units=num_hidden_units,\n",
    "                                  activation_fn=tf.nn.relu,\n",
    "                                  n_classes=num_classes,\n",
    "                                  model_dir=\"./Checkpoints/checkpoints_tutorial17-1/\")\n",
    "                                   #model_dir=\"./checkpoints_tutorial17-1/\")\n",
    "                                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now it's time to train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./Checkpoints/checkpoints_tutorial17-1/model.ckpt.\n",
      "INFO:tensorflow:loss = 298.03534, step = 1\n",
      "INFO:tensorflow:global_step/sec: 110.976\n",
      "INFO:tensorflow:loss = 24.321064, step = 101 (0.903 sec)\n",
      "INFO:tensorflow:global_step/sec: 108.484\n",
      "INFO:tensorflow:loss = 24.434456, step = 201 (0.920 sec)\n",
      "INFO:tensorflow:global_step/sec: 111.714\n",
      "INFO:tensorflow:loss = 28.53651, step = 301 (0.897 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.35\n",
      "INFO:tensorflow:loss = 10.151123, step = 401 (0.890 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.114\n",
      "INFO:tensorflow:loss = 11.103088, step = 501 (0.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 106.087\n",
      "INFO:tensorflow:loss = 10.291996, step = 601 (0.943 sec)\n",
      "INFO:tensorflow:global_step/sec: 109.783\n",
      "INFO:tensorflow:loss = 9.709423, step = 701 (0.911 sec)\n",
      "INFO:tensorflow:global_step/sec: 109.685\n",
      "INFO:tensorflow:loss = 6.4357643, step = 801 (0.912 sec)\n",
      "INFO:tensorflow:global_step/sec: 92.835\n",
      "INFO:tensorflow:loss = 20.01784, step = 901 (1.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 90.2457\n",
      "INFO:tensorflow:loss = 6.646566, step = 1001 (1.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.544\n",
      "INFO:tensorflow:loss = 2.5655975, step = 1101 (0.966 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.6718\n",
      "INFO:tensorflow:loss = 3.2528563, step = 1201 (1.046 sec)\n",
      "INFO:tensorflow:global_step/sec: 92.3302\n",
      "INFO:tensorflow:loss = 8.362395, step = 1301 (1.081 sec)\n",
      "INFO:tensorflow:global_step/sec: 86.5831\n",
      "INFO:tensorflow:loss = 5.6131263, step = 1401 (1.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.9228\n",
      "INFO:tensorflow:loss = 5.641927, step = 1501 (1.087 sec)\n",
      "INFO:tensorflow:global_step/sec: 109.624\n",
      "INFO:tensorflow:loss = 11.723446, step = 1601 (0.914 sec)\n",
      "INFO:tensorflow:global_step/sec: 96.403\n",
      "INFO:tensorflow:loss = 13.276176, step = 1701 (1.036 sec)\n",
      "INFO:tensorflow:global_step/sec: 99.3325\n",
      "INFO:tensorflow:loss = 3.3140042, step = 1801 (1.006 sec)\n",
      "INFO:tensorflow:global_step/sec: 106.117\n",
      "INFO:tensorflow:loss = 3.7367804, step = 1901 (0.943 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into ./Checkpoints/checkpoints_tutorial17-1/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 8.220387.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x10f620750>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We use the model.train function the train the model. \n",
    "# Here we also set the input function\n",
    "model.train(input_fn=train_input_fn, steps=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this standardized code it is really easy to create a new model with different settings and test how good it performs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_hidden_units2 =[1024, 512, 256] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x125d80f10>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': './checkpoints_tutorial3/', '_save_summary_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "model2 = tf.estimator.DNNClassifier(feature_columns=feature_columns,\n",
    "                                  hidden_units=num_hidden_units2,\n",
    "                                  activation_fn=tf.nn.relu,\n",
    "                                  optimizer=tf.train.ProximalAdagradOptimizer(\n",
    "                                  learning_rate=0.1,\n",
    "                                  l1_regularization_strength=0.001\n",
    "                                  ),\n",
    "                                  n_classes=num_classes,\n",
    "                                  model_dir=\"./checkpoints_tutorial3/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./checkpoints_tutorial3/model.ckpt.\n",
      "INFO:tensorflow:loss = 302.3125, step = 1\n",
      "INFO:tensorflow:global_step/sec: 43.033\n",
      "INFO:tensorflow:loss = 134.62091, step = 101 (2.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.9707\n",
      "INFO:tensorflow:loss = 54.968197, step = 201 (2.705 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.9301\n",
      "INFO:tensorflow:loss = 63.9155, step = 301 (3.038 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.204\n",
      "INFO:tensorflow:loss = 51.93029, step = 401 (2.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.6646\n",
      "INFO:tensorflow:loss = 71.32415, step = 501 (2.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.4938\n",
      "INFO:tensorflow:loss = 44.90232, step = 601 (2.986 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.4974\n",
      "INFO:tensorflow:loss = 21.217262, step = 701 (2.900 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.6747\n",
      "INFO:tensorflow:loss = 45.02545, step = 801 (4.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.5981\n",
      "INFO:tensorflow:loss = 27.771957, step = 901 (3.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.3786\n",
      "INFO:tensorflow:loss = 40.593487, step = 1001 (3.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.4538\n",
      "INFO:tensorflow:loss = 47.917274, step = 1101 (2.819 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.1259\n",
      "INFO:tensorflow:loss = 45.268158, step = 1201 (2.768 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.1841\n",
      "INFO:tensorflow:loss = 34.853165, step = 1301 (2.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.7045\n",
      "INFO:tensorflow:loss = 29.348057, step = 1401 (2.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.2331\n",
      "INFO:tensorflow:loss = 29.656754, step = 1501 (3.813 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.8659\n",
      "INFO:tensorflow:loss = 29.002089, step = 1601 (4.794 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.0893\n",
      "INFO:tensorflow:loss = 23.213852, step = 1701 (4.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.367\n",
      "INFO:tensorflow:loss = 30.77126, step = 1801 (4.680 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.5833\n",
      "INFO:tensorflow:loss = 19.341204, step = 1901 (4.068 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into ./checkpoints_tutorial3/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 21.033934.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x126535550>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.train(input_fn=train_input_fn, steps=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training the first thing we want to do is evaluate the model that we have build. We will be evaluating the model using the test input function that we have build. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-03-01-19:30:12\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoints_tutorial12/model.ckpt-4000\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-01-19:30:13\n",
      "INFO:tensorflow:Saving dict for global step 4000: accuracy = 0.9713, average_loss = 0.09161571, global_step = 4000, loss = 11.596925\n"
     ]
    }
   ],
   "source": [
    "# Here we set the model.evaluate and specify it to use the test_input_fn\n",
    "result = model.evaluate(input_fn=test_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9713,\n",
       " 'average_loss': 0.09161571,\n",
       " 'global_step': 4000,\n",
       " 'loss': 11.596925}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print the results\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy: 97.13%\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification accuracy: {0:.2%}\".format(result[\"accuracy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-03-01-19:44:56\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoints_tutorial3/model.ckpt-2000\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-01-19:44:58\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.9379, average_loss = 0.21088672, global_step = 2000, loss = 26.69452\n"
     ]
    }
   ],
   "source": [
    "result2 = model2.evaluate(input_fn=test_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9379,\n",
       " 'average_loss': 0.21088672,\n",
       " 'global_step': 2000,\n",
       " 'loss': 26.69452}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy: 93.79%\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification accuracy: {0:.2%}\".format(result2[\"accuracy\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are happy with the accuracy of our model we can do a couple of predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here we specify the model predict function. \n",
    "predictions = model.predict(input_fn=predict_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoints_tutorial17-1/model.ckpt-6000\n"
     ]
    }
   ],
   "source": [
    "cls = [p['classes'] for p in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, 0, 4, 1, 4, 9, 5])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_pred = np.array(cls, dtype='int').squeeze()\n",
    "cls_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU0AAAD5CAYAAACj3GcTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0hQRCUGVpohICP8feUeis2qxGaoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c90ba50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Let's plot our predictions\n",
    "plot_images(images=some_images,\n",
    "            cls_true=some_images_cls,\n",
    "            cls_pred=cls_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
